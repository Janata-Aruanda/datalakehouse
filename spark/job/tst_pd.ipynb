{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b737ffe5-3d97-4531-a8fb-1b50d27ee66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta teste criada no bucket raw\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Carregar configurações do arquivo JSON\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Configurar o cliente S3 usando as configurações do arquivo JSON\n",
    "s3 = boto3.client('s3',\n",
    "                  endpoint_url=config['aws_endpoint'],\n",
    "                  aws_access_key_id=config['aws_access_key_id'],\n",
    "                  aws_secret_access_key=config['aws_secret_access_key'],\n",
    "                  region_name='us-east-1',  # Ou a região apropriada\n",
    "                  )\n",
    "\n",
    "# Nome do bucket onde será criada a \"pasta\"\n",
    "bucket_name = 'raw'\n",
    "\n",
    "# Nome da \"pasta\" que deseja criar\n",
    "folder_name = 'teste'\n",
    "\n",
    "# Adicionar um objeto vazio que representará a \"pasta\" no S3\n",
    "# A \"pasta\" será representada por um objeto sem conteúdo, apenas o nome do objeto\n",
    "# No S3, um objeto com a key 'raw/' indicará a \"pasta\" chamada 'raw'\n",
    "s3.put_object(Bucket=bucket_name, Key=folder_name)\n",
    "\n",
    "print(f'Pasta {folder_name} criada no bucket {bucket_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02e2db9-6867-465d-bb7a-b8ba5ac8f761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo basedata.csv salvo no bucket raw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Dados de exemplo para o DataFrame\n",
    "data = {\n",
    "    'Nome': ['João', 'Maria', 'José'],\n",
    "    'Idade': [30, 25, 40],\n",
    "    'Cidade': ['São Paulo', 'Rio de Janeiro', 'Belo Horizonte']\n",
    "}\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Nome do arquivo CSV temporário local\n",
    "temp_csv_file = 'temp_data.csv'\n",
    "\n",
    "# Salvar DataFrame como CSV localmente\n",
    "df.to_csv(temp_csv_file, index=False)\n",
    "\n",
    "# Carregar configurações do arquivo JSON\n",
    "with open('config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Configurar o cliente S3 usando as configurações do arquivo JSON\n",
    "s3 = boto3.client('s3',\n",
    "                  endpoint_url=config['aws_endpoint'],\n",
    "                  aws_access_key_id=config['aws_access_key_id'],\n",
    "                  aws_secret_access_key=config['aws_secret_access_key'],\n",
    "                  region_name='us-east-1'  # Ou a região apropriada\n",
    "                  )\n",
    "\n",
    "# Nome do bucket onde você deseja salvar o arquivo\n",
    "bucket_name = 'raw'\n",
    "\n",
    "# Caminho dentro do bucket onde você deseja salvar o arquivo\n",
    "folder_name = 'base'\n",
    "\n",
    "# Nome do arquivo no S3\n",
    "s3_file_name = folder_name + 'data.csv'\n",
    "\n",
    "# Fazer upload do arquivo CSV para o S3\n",
    "s3.upload_file(temp_csv_file, bucket_name, s3_file_name)\n",
    "\n",
    "print(f'Arquivo {s3_file_name} salvo no bucket {bucket_name}')\n",
    "\n",
    "# Remover arquivo CSV temporário local\n",
    "os.remove(temp_csv_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
